#!/bin/bash

# Script de test pour valider l'architecture de traitement distribuÃ©

set -e

echo "ğŸ§ª Tests de validation de l'architecture"
echo "========================================"

# Couleurs pour les messages
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Fonction pour afficher les rÃ©sultats
print_result() {
    if [ $1 -eq 0 ]; then
        echo -e "${GREEN}âœ… $2${NC}"
    else
        echo -e "${RED}âŒ $2${NC}"
        FAILED_TESTS=$((FAILED_TESTS + 1))
    fi
}

FAILED_TESTS=0

# Test 1: VÃ©rifier que tous les services sont en cours d'exÃ©cution
echo "1. VÃ©rification de l'Ã©tat des services..."
SERVICES=("namenode" "secondary-nn" "datanode-1" "datanode-2" "datanode-3" "spark-thrift" "metastore" "mongodb" "mongo-express" "app")

for service in "${SERVICES[@]}"; do
    if docker-compose ps | grep -q "$service.*Up"; then
        print_result 0 "Service $service est en cours d'exÃ©cution"
    else
        print_result 1 "Service $service n'est pas en cours d'exÃ©cution"
    fi
done

# Test 2: VÃ©rifier HDFS
echo -e "\n2. Test de HDFS..."
if docker exec namenode hdfs dfsadmin -report > /dev/null 2>&1; then
    print_result 0 "HDFS NameNode est accessible"
    
    # VÃ©rifier les DataNodes
    DN_COUNT=$(docker exec namenode hdfs dfsadmin -report | grep "Live datanodes" | awk '{print $3}')
    if [ "$DN_COUNT" -eq 3 ]; then
        print_result 0 "3 DataNodes sont actifs"
    else
        print_result 1 "Seulement $DN_COUNT DataNodes sont actifs (attendu: 3)"
    fi
else
    print_result 1 "HDFS NameNode n'est pas accessible"
fi

# Test 3: VÃ©rifier YARN
echo -e "\n3. Test de YARN..."
if docker exec namenode yarn node -list > /dev/null 2>&1; then
    print_result 0 "YARN ResourceManager est accessible"
    
    # VÃ©rifier les NodeManagers
    NM_COUNT=$(docker exec namenode yarn node -list | grep "RUNNING" | wc -l)
    if [ "$NM_COUNT" -eq 3 ]; then
        print_result 0 "3 NodeManagers sont actifs"
    else
        print_result 1 "Seulement $NM_COUNT NodeManagers sont actifs (attendu: 3)"
    fi
else
    print_result 1 "YARN ResourceManager n'est pas accessible"
fi

# Test 4: VÃ©rifier Spark
echo -e "\n4. Test de Spark..."
if docker exec namenode curl -s http://localhost:8080 > /dev/null 2>&1; then
    print_result 0 "Spark Master est accessible"
    
    # VÃ©rifier les Workers
    WORKER_COUNT=$(docker exec namenode curl -s http://localhost:8080 | grep -o "Workers" | wc -l)
    if [ "$WORKER_COUNT" -gt 0 ]; then
        print_result 0 "Spark Workers sont connectÃ©s"
    else
        print_result 1 "Aucun Spark Worker n'est connectÃ©"
    fi
else
    print_result 1 "Spark Master n'est pas accessible"
fi

# Test 5: VÃ©rifier MongoDB
echo -e "\n5. Test de MongoDB..."
if docker exec mongodb mongo --eval "db.adminCommand('ping')" > /dev/null 2>&1; then
    print_result 0 "MongoDB est accessible"
    
    # VÃ©rifier les donnÃ©es
    DOC_COUNT=$(docker exec mongodb mongo retail --eval "db.sales.count()" --quiet)
    if [ "$DOC_COUNT" -gt 0 ]; then
        print_result 0 "Collection sales contient $DOC_COUNT documents"
    else
        print_result 1 "Collection sales est vide"
    fi
else
    print_result 1 "MongoDB n'est pas accessible"
fi

# Test 6: VÃ©rifier Spark Thrift Server
echo -e "\n6. Test de Spark Thrift Server..."
sleep 10  # Attendre que le service soit prÃªt
if docker exec spark-thrift netstat -tlnp | grep -q ":10000"; then
    print_result 0 "Spark Thrift Server Ã©coute sur le port 10000"
else
    print_result 1 "Spark Thrift Server n'Ã©coute pas sur le port 10000"
fi

# Test 7: VÃ©rifier l'application Streamlit
echo -e "\n7. Test de l'application Streamlit..."
sleep 10  # Attendre que l'application soit prÃªte
if docker exec app netstat -tlnp | grep -q ":8501"; then
    print_result 0 "Application Streamlit Ã©coute sur le port 8501"
else
    print_result 1 "Application Streamlit n'Ã©coute pas sur le port 8501"
fi

# Test 8: VÃ©rifier les donnÃ©es HDFS
echo -e "\n8. Test des donnÃ©es HDFS..."
if docker exec namenode hdfs dfs -test -d /data/raw/sales 2>/dev/null; then
    print_result 0 "RÃ©pertoire /data/raw/sales existe dans HDFS"
    
    # VÃ©rifier les fichiers Parquet
    FILE_COUNT=$(docker exec namenode hdfs dfs -ls /data/raw/sales | grep -c "parquet")
    if [ "$FILE_COUNT" -gt 0 ]; then
        print_result 0 "Fichiers Parquet trouvÃ©s dans /data/raw/sales"
    else
        print_result 1 "Aucun fichier Parquet trouvÃ© dans /data/raw/sales"
    fi
else
    print_result 1 "RÃ©pertoire /data/raw/sales n'existe pas dans HDFS"
fi

# Test 9: VÃ©rifier les tables Hive
echo -e "\n9. Test des tables Hive..."
if docker exec spark-thrift beeline -u jdbc:hive2://localhost:10000 -e "SHOW TABLES;" 2>/dev/null | grep -q "raw_sales"; then
    print_result 0 "Table raw_sales existe dans Hive"
    
    # VÃ©rifier le contenu de la table
    ROW_COUNT=$(docker exec spark-thrift beeline -u jdbc:hive2://localhost:10000 -e "SELECT COUNT(*) FROM raw_sales;" 2>/dev/null | grep -v "INFO" | tail -1)
    if [ "$ROW_COUNT" -gt 0 ]; then
        print_result 0 "Table raw_sales contient $ROW_COUNT lignes"
    else
        print_result 1 "Table raw_sales est vide"
    fi
else
    print_result 1 "Table raw_sales n'existe pas dans Hive"
fi

# Test 10: Test de performance simple
echo -e "\n10. Test de performance..."
start_time=$(date +%s)
docker exec spark-thrift beeline -u jdbc:hive2://localhost:10000 -e "SELECT category, COUNT(*) FROM raw_sales GROUP BY category;" > /dev/null 2>&1
end_time=$(date +%s)
duration=$((end_time - start_time))

if [ "$duration" -lt 30 ]; then
    print_result 0 "RequÃªte SQL exÃ©cutÃ©e en ${duration}s (acceptable)"
else
    print_result 1 "RequÃªte SQL trop lente: ${duration}s"
fi

# RÃ©sumÃ© des tests
echo -e "\nğŸ“Š RÃ©sumÃ© des tests"
echo "=================="

if [ "$FAILED_TESTS" -eq 0 ]; then
    echo -e "${GREEN}ğŸ‰ Tous les tests sont passÃ©s avec succÃ¨s!${NC}"
    echo -e "${GREEN}L'architecture est opÃ©rationnelle et prÃªte Ã  Ãªtre utilisÃ©e.${NC}"
else
    echo -e "${RED}âš ï¸  $FAILED_TESTS test(s) ont Ã©chouÃ©.${NC}"
    echo -e "${YELLOW}VÃ©rifiez les logs des services et relancez les tests.${NC}"
fi

echo -e "\nğŸ”— Interfaces disponibles:"
echo "  - Dashboard: http://localhost:8501"
echo "  - HDFS NameNode: http://localhost:9870"
echo "  - YARN ResourceManager: http://localhost:8088"
echo "  - Spark Master: http://localhost:8080"
echo "  - MongoDB Express: http://localhost:8089"

echo -e "\nğŸ“ Commandes utiles:"
echo "  - Logs: docker-compose logs -f [service]"
echo "  - RedÃ©marrer: docker-compose restart [service]"
echo "  - ArrÃªter: docker-compose down"

