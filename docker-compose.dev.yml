version: "3.9"

networks:
  bigdata_net_dev:
    driver: bridge

volumes:
  hdfs_namenode_dev:
  hdfs_datanode_dev_1:
  hdfs_datanode_dev_2:
  hdfs_datanode_dev_3:
  metastore_db_dev:
  mongo_data_dev:

services:
  namenode:
    build: ./hadoop/namenode
    container_name: namenode-dev
    hostname: namenode
    environment:
      - CLUSTER_NAME=dev-cluster
      - HDFS_REPLICATION=2
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1g
    ports:
      - "9870:9870"    # HDFS NN UI
      - "8088:8088"    # YARN RM UI
      - "7077:7077"    # Spark master RPC
      - "8080:8080"    # Spark master UI
    volumes:
      - hdfs_namenode_dev:/hadoop/dfs/name
      - ./connectors:/opt/connectors
      - ./hadoop:/opt/hadoop/conf
      - ./logs:/var/log/hadoop
    networks:
      - bigdata_net_dev
    restart: unless-stopped

  secondary-nn:
    build: ./hadoop/secondary-nn
    container_name: secondary-nn-dev
    hostname: secondary-nn
    networks: [bigdata_net_dev]
    restart: unless-stopped

  datanode-1:
    build: ./hadoop/datanode
    container_name: datanode-1-dev
    hostname: datanode-1
    environment:
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=1g
    ports:
      - "9864:9864"
      - "8081:8081"    # Spark worker UI
    volumes:
      - hdfs_datanode_dev_1:/hadoop/dfs/data
      - ./hadoop:/opt/hadoop/conf
      - ./logs:/var/log/hadoop
    networks: [bigdata_net_dev]
    restart: unless-stopped

  datanode-2:
    build: ./hadoop/datanode
    container_name: datanode-2-dev
    hostname: datanode-2
    ports:
      - "8082:8081"
    volumes:
      - hdfs_datanode_dev_2:/hadoop/dfs/data
      - ./hadoop:/opt/hadoop/conf
      - ./logs:/var/log/hadoop
    networks: [bigdata_net_dev]
    restart: unless-stopped

  datanode-3:
    build: ./hadoop/datanode
    container_name: datanode-3-dev
    hostname: datanode-3
    ports:
      - "8083:8081"
    volumes:
      - hdfs_datanode_dev_3:/hadoop/dfs/data
      - ./hadoop:/opt/hadoop/conf
      - ./logs:/var/log/hadoop
    networks: [bigdata_net_dev]
    restart: unless-stopped

  spark-thrift:
    build: ./spark/thrift
    container_name: spark-thrift-dev
    environment:
      - HIVE_METASTORE_URI=thrift://metastore:9083
      - SPARK_DRIVER_MEMORY=512m
    ports:
      - "10000:10000"  # JDBC
    depends_on: [namenode, metastore]
    networks: [bigdata_net_dev]
    restart: unless-stopped
    volumes:
      - ./spark/scripts:/opt/spark/scripts
      - ./logs:/var/log/spark

  metastore:
    build: ./hive/metastore
    container_name: metastore-dev
    volumes:
      - metastore_db_dev:/var/lib/postgresql/data
    networks: [bigdata_net_dev]
    restart: unless-stopped

  pig:
    build: ./pig
    container_name: pig-dev
    networks: [bigdata_net_dev]
    volumes:
      - ./pig/scripts:/scripts
      - ./logs:/var/log/pig
    restart: unless-stopped

  mongodb:
    image: mongo:7
    container_name: mongodb-dev
    ports:
      - "27017:27017"
    volumes:
      - mongo_data_dev:/data/db
      - ./mongo/init.js:/docker-entrypoint-initdb.d/init.js:ro
      - ./logs:/var/log/mongodb
    networks: [bigdata_net_dev]
    restart: unless-stopped
    environment:
      - MONGO_INITDB_DATABASE=retail_dev

  mongo-express:
    image: mongo-express:1
    container_name: mongo-express-dev
    environment:
      - ME_CONFIG_MONGODB_SERVER=mongodb
      - ME_CONFIG_MONGODB_DATABASE=retail_dev
    ports:
      - "8089:8081"
    depends_on: [mongodb]
    networks: [bigdata_net_dev]
    restart: unless-stopped

  app:
    build: ./app
    container_name: app-dev
    env_file:
      - env.development
    environment:
      - JDBC_URL=jdbc:hive2://spark-thrift:10000/default
      - DEBUG_MODE=true
    ports:
      - "8501:8501"
    depends_on: [spark-thrift]
    networks: [bigdata_net_dev]
    restart: unless-stopped
    volumes:
      - ./app:/app
      - ./logs:/var/log/app
    # Hot reload pour le développement
    command: ["streamlit", "run", "app.py", "--server.port", "8501", "--server.address", "0.0.0.0", "--server.runOnSave", "true"]

  # Service de développement pour les tests
  dev-tools:
    image: openjdk:11-jre-slim
    container_name: dev-tools
    volumes:
      - ./:/workspace
      - ./logs:/var/log/dev
    working_dir: /workspace
    networks: [bigdata_net_dev]
    command: ["tail", "-f", "/dev/null"]
    restart: unless-stopped

