#!/bin/bash

echo "üöÄ Test des Workers Spark"
echo "========================="

# V√©rifier l'√©tat du cluster Spark
echo "1. V√©rification du Spark Master..."
if curl -s http://localhost:8085 > /dev/null; then
    echo "‚úÖ Spark Master accessible"
    WORKERS=$(curl -s http://localhost:8085/json/ | grep -o '"workers" : \[[^]]*\]' | grep -o '\[.*\]')
    if [ "$WORKERS" = "[]" ]; then
        echo "‚ö†Ô∏è  Aucun worker connect√©"
    else
        echo "‚úÖ Workers connect√©s: $WORKERS"
    fi
else
    echo "‚ùå Spark Master non accessible"
fi

echo ""
echo "2. Test du traitement distribu√©..."
echo "   Ex√©cution de l'exemple de travail Spark..."

# Ex√©cuter l'exemple de travail
docker exec spark-processor python /app/exemple-travail-complet.py

echo ""
echo "3. V√©rification des r√©sultats sur HDFS..."
echo "   Les r√©sultats sont sauvegard√©s dans:"
echo "   - hdfs://namenode:9000/spark-results/ventes-par-categorie"
echo "   - hdfs://namenode:9000/spark-results/top-produits"
echo "   - hdfs://namenode:9000/spark-results/utilisateurs-actifs"
echo "   - hdfs://namenode:9000/spark-results/tendances-temporelles"

echo ""
echo "4. Acc√®s aux interfaces web:"
echo "   - Spark Master UI: http://localhost:8085"
echo "   - HDFS NameNode: http://localhost:9870"
echo "   - Application Streamlit: http://localhost:8501"

echo ""
echo "‚úÖ Test termin√© !"
