#!/bin/bash

echo "ğŸš€ CLUSTER DE TRAITEMENT DISTRIBUÃ‰ - STATUT COMPLET"
echo "=================================================="
echo ""

# Couleurs
GREEN='\033[0;32m'
RED='\033[0;31m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m'

echo -e "${CYAN}ğŸ“Š SERVICES DOCKER EN COURS D'EXÃ‰CUTION${NC}"
echo "----------------------------------------"
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep -E "(mongodb|mongo-express|app|namenode|datanode|secondary-nn|spark-thrift|metastore|pig|mongo-exporter)"

echo ""
echo -e "${CYAN}ğŸ—„ï¸ DONNÃ‰ES MONGODB${NC}"
echo "-------------------"
doc_count=$(docker exec mongodb mongosh retail --eval "db.sales.countDocuments()" --quiet 2>/dev/null)
if [ ! -z "$doc_count" ] && [ "$doc_count" -gt 0 ]; then
    echo -e "${GREEN}âœ… Documents MongoDB: $doc_count${NC}"
else
    echo -e "${RED}âŒ Aucun document trouvÃ©${NC}"
fi

echo ""
echo -e "${CYAN}ğŸ“ SYSTÃˆME DE FICHIERS HDFS${NC}"
echo "------------------------------"
if docker exec namenode hdfs dfs -ls /data/ >/dev/null 2>&1; then
    echo -e "${GREEN}âœ… RÃ©pertoires HDFS crÃ©Ã©s${NC}"
    echo "   - /data/raw/sales/ (donnÃ©es brutes)"
    echo "   - /data/curated/sales/ (donnÃ©es transformÃ©es)"
else
    echo -e "${YELLOW}âš ï¸ RÃ©pertoires HDFS en cours de crÃ©ation${NC}"
fi

echo ""
echo -e "${CYAN}ğŸŒ INTERFACES WEB DISPONIBLES${NC}"
echo "--------------------------------"

# Test des interfaces web
interfaces=(
    "HDFS NameNode:http://localhost:9870"
    "YARN ResourceManager:http://localhost:8088"
    "Spark Master:http://localhost:8080"
    "MongoDB Express:http://localhost:8089"
    "Application Streamlit:http://localhost:8501"
)

for interface in "${interfaces[@]}"; do
    name=$(echo $interface | cut -d: -f1)
    url=$(echo $interface | cut -d: -f2-)
    if curl -s "$url" >/dev/null 2>&1; then
        echo -e "${GREEN}âœ… $name${NC}"
    else
        echo -e "${YELLOW}âš ï¸ $name${NC}"
    fi
done

echo ""
echo -e "${CYAN}ğŸ”„ SERVICE D'EXPORT AUTOMATIQUE${NC}"
echo "-----------------------------------"
if docker ps | grep -q "mongo-exporter.*Up"; then
    echo -e "${GREEN}âœ… Service d'export automatique en cours d'exÃ©cution${NC}"
    echo "   - Export MongoDB â†’ HDFS toutes les 5 minutes"
    echo "   - Logs: docker logs -f mongo-exporter"
else
    echo -e "${RED}âŒ Service d'export automatique non en cours d'exÃ©cution${NC}"
fi

echo ""
echo -e "${CYAN}ğŸ”Œ PORTS DE SERVICE${NC}"
echo "----------------------"
echo "   - MongoDB: localhost:27018"
echo "   - Spark Thrift Server: localhost:10000"
echo "   - Hive Metastore: localhost:5434"

echo ""
echo -e "${CYAN}ğŸ¯ COMMANDES UTILES${NC}"
echo "----------------------"
echo -e "${PURPLE}ğŸ“Š Voir les logs d'un service:${NC}"
echo "   docker logs -f <nom_du_service>"
echo ""
echo -e "${PURPLE}ğŸ”§ AccÃ©der Ã  un conteneur:${NC}"
echo "   docker exec -it <nom_du_service> bash"
echo ""
echo -e "${PURPLE}ğŸ“ VÃ©rifier HDFS:${NC}"
echo "   docker exec namenode hdfs dfs -ls /data/"
echo ""
echo -e "${PURPLE}ğŸ· Tester Pig:${NC}"
echo "   docker exec pig pig -x mapreduce /scripts/eda.pig"
echo ""
echo -e "${PURPLE}ğŸ“ˆ Tester Spark:${NC}"
echo "   docker exec spark-thrift spark-sql --master spark://namenode:7077"
echo ""

echo -e "${GREEN}âœ… CLUSTER OPÃ‰RATIONNEL !${NC}"
echo ""
echo -e "${BLUE}ğŸ‰ Le cluster de traitement distribuÃ© est prÃªt Ã  traiter vos donnÃ©es !${NC}"

