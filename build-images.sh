#!/bin/bash

# Script pour construire toutes les images Docker nÃ©cessaires
# Architecture de traitement distribuÃ©

set -e

echo "ğŸ”¨ Construction des images Docker"
echo "================================="

# VÃ©rifier que Docker est installÃ©
if ! command -v docker &> /dev/null; then
    echo "âŒ Docker n'est pas installÃ©. Veuillez installer Docker."
    exit 1
fi

# Construire l'image de base Hadoop/Spark
echo "ğŸ—ï¸  Construction de l'image de base Hadoop/Spark..."
docker build -t hadoop-base:latest ./hadoop/base/

# Construire l'image NameNode
echo "ğŸ—ï¸  Construction de l'image NameNode..."
docker build -t namenode:latest ./hadoop/namenode/

# Construire l'image Secondary NameNode
echo "ğŸ—ï¸  Construction de l'image Secondary NameNode..."
docker build -t secondary-nn:latest ./hadoop/secondary-nn/

# Construire l'image DataNode
echo "ğŸ—ï¸  Construction de l'image DataNode..."
docker build -t datanode:latest ./hadoop/datanode/

# Construire l'image Spark Thrift Server
echo "ğŸ—ï¸  Construction de l'image Spark Thrift Server..."
docker build -t spark-thrift:latest ./spark/thrift/

# Construire l'image Hive Metastore
echo "ğŸ—ï¸  Construction de l'image Hive Metastore..."
docker build -t metastore:latest ./hive/metastore/

# Construire l'image Pig
echo "ğŸ—ï¸  Construction de l'image Pig..."
docker build -t pig:latest ./pig/

echo ""
echo "âœ… Toutes les images ont Ã©tÃ© construites avec succÃ¨s!"
echo ""
echo "ğŸ“‹ Images construites:"
echo "  - hadoop-base:latest"
echo "  - namenode:latest"
echo "  - secondary-nn:latest"
echo "  - datanode:latest"
echo "  - spark-thrift:latest"
echo "  - metastore:latest"
echo "  - pig:latest"
echo ""
echo "ğŸš€ Vous pouvez maintenant dÃ©marrer l'architecture complÃ¨te avec:"
echo "  docker-compose up -d"

