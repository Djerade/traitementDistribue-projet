#!/bin/bash

echo "ðŸš€ Test Final des Workers Spark"
echo "==============================="

echo ""
echo "1. VÃ©rification de l'Ã©tat du cluster..."
echo "   - Spark Master: http://localhost:8085"
echo "   - HDFS NameNode: http://localhost:9870"
echo "   - Application Streamlit: http://localhost:8501"

echo ""
echo "2. Test du traitement Spark local..."
docker exec app bash -c "export JAVA_HOME=/usr/lib/jvm/java-21-openjdk-amd64 && python /app/exemple-simple.py"

echo ""
echo "3. Exemples de travail que les Workers Spark peuvent effectuer :"
echo ""
echo "ðŸ“Š ANALYSES POSSIBLES :"
echo "   - Analyse des ventes par catÃ©gorie"
echo "   - Top produits les plus vendus"
echo "   - Utilisateurs les plus actifs"
echo "   - Tendances temporelles"
echo "   - DÃ©tection de patterns"
echo "   - Segmentation des clients"
echo "   - PrÃ©diction de tendances"
echo "   - CorrÃ©lations entre produits"

echo ""
echo "ðŸ”§ CONFIGURATION DES WORKERS :"
echo "   - Worker 1: 2G RAM, 2 cores (Port 8091)"
echo "   - Worker 2: 1G RAM, 1 core (Port 8092)"
echo "   - Worker 3: 1G RAM, 1 core (Port 8093)"

echo ""
echo "ðŸ’» UTILISATION :"
echo "   - Via l'application Streamlit: http://localhost:8501"
echo "   - Page 'âš¡ Analyses Spark'"
echo "   - SÃ©lection du type d'analyse"
echo "   - ContrÃ´le de la taille d'Ã©chantillon"

echo ""
echo "ðŸ“ˆ AVANTAGES DU TRAITEMENT DISTRIBUÃ‰ :"
echo "   - Traitement parallÃ¨le de grandes quantitÃ©s de donnÃ©es"
echo "   - ScalabilitÃ© horizontale"
echo "   - TolÃ©rance aux pannes"
echo "   - Performance optimisÃ©e"
echo "   - RÃ©partition de charge automatique"

echo ""
echo "âœ… Test terminÃ© avec succÃ¨s !"
echo ""
echo "ðŸŽ¯ Prochaines Ã©tapes :"
echo "   1. DÃ©marrer les workers Spark : docker-compose up -d spark-worker-1 spark-worker-2 spark-worker-3"
echo "   2. Utiliser l'application Streamlit pour les analyses"
echo "   3. Monitorer via Spark Master UI"
echo "   4. Sauvegarder les rÃ©sultats sur HDFS"
