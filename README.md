# Architecture Technique â€“ Traitement DistribuÃ© (Docker)

> **Cible** : Cluster Hadoop/Spark (1 master, 1 secondary-master, 3 slaves) + Pig pour EDA + lecture MongoDBâ†’Hadoop + application dynamique + workflow et livrables.

## ğŸ—ï¸ Vue d'ensemble

Cette architecture implÃ©mente un systÃ¨me de traitement distribuÃ© complet avec les composants suivants :

```
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚        Poste Dev/Client      â”‚
                   â”‚  (navigateur + VSCode)       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                     Docker Network: bigdata_net (bridge)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Cluster Hadoop + Spark + Pig + MongoDB + App                        â”‚
â”‚                                                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ namenode     â”‚   â”‚ secondary-nn   â”‚     â”‚ datanode-1     â”‚     â”‚ datanode-2     â”‚   â”‚
â”‚  â”‚ + resourcemgrâ”‚   â”‚ + journalnode  â”‚     â”‚ + nodemanager   â”‚     â”‚ + nodemanager   â”‚   â”‚
â”‚  â”‚ + spark-master â”‚ â”‚                â”‚     â”‚ + spark-worker  â”‚     â”‚ + spark-worker  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚         â”‚                    â”‚                      â”‚                      â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€ HDFS HA (JournalNodes/ZKFC) â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                                                                     â”‚                   â”‚
â”‚                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                                        â”‚ datanode-3 + nodemanager + spark-worker    â”‚   â”‚
â”‚                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Pig (client)         â”‚<--->â”‚ Spark Thrift Server â”‚<--->â”‚ Hive Metastore (option)  â”‚  â”‚
â”‚  â”‚ (mapreduce mode)     â”‚     â”‚ (JDBC/SQL)          â”‚     â”‚ + Derby/Postgres         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚ MongoDB (replica set 1-node)  â”‚  â† volumes
â”‚  â”‚ + mongo-express (option)      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â”‚ App dynamique (Streamlit/Flaskâ”‚ â†’ lit via Spark Thrift JDBC ou WebHDFS / parquet
â”‚  â”‚  + API)                        â”‚ â†’ Ã©crit rÃ©sultats vers HDFS/MinIO(option)
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis
- Docker et Docker Compose installÃ©s
- Au moins 8 Go de RAM disponible
- 20 Go d'espace disque libre

### Installation et dÃ©marrage

1. **Cloner le projet**
```bash
git clone <repository-url>
cd traitementDistribue-projet
```

2. **Lancer l'architecture complÃ¨te**
```bash
chmod +x start-cluster.sh
./start-cluster.sh
```

3. **AccÃ©der aux interfaces**
- **Dashboard principal** : http://localhost:8501
- **HDFS NameNode** : http://localhost:9870
- **YARN ResourceManager** : http://localhost:8088
- **Spark Master** : http://localhost:8080
- **MongoDB Express** : http://localhost:8089

## ğŸ“ Structure du projet

```
/bigdata-project
â”œâ”€â”€ docker-compose.yml          # Orchestration des services
â”œâ”€â”€ start-cluster.sh            # Script de dÃ©marrage automatique
â”œâ”€â”€ env.example                 # Variables d'environnement
â”œâ”€â”€ hadoop/
â”‚   â”œâ”€â”€ base/Dockerfile         # Image de base Hadoop/Spark
â”‚   â”œâ”€â”€ namenode/               # NameNode + ResourceManager + Spark Master
â”‚   â”œâ”€â”€ datanode/               # DataNode + NodeManager + Spark Worker
â”‚   â”œâ”€â”€ secondary-nn/           # Secondary NameNode
â”‚   â””â”€â”€ *.xml                   # Configurations Hadoop
â”œâ”€â”€ spark/
â”‚   â”œâ”€â”€ thrift/Dockerfile       # Spark Thrift Server
â”‚   â””â”€â”€ scripts/                # Scripts Spark (ingestion MongoDBâ†’HDFS)
â”œâ”€â”€ pig/
â”‚   â”œâ”€â”€ Dockerfile              # Client Pig
â”‚   â””â”€â”€ scripts/                # Scripts Pig EDA
â”œâ”€â”€ hive/
â”‚   â”œâ”€â”€ metastore/Dockerfile    # Hive Metastore (PostgreSQL)
â”‚   â””â”€â”€ hive-site.xml           # Configuration Hive
â”œâ”€â”€ mongo/
â”‚   â””â”€â”€ init.js                 # DonnÃ©es d'exemple MongoDB
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ Dockerfile              # Application Streamlit
â”‚   â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”‚   â””â”€â”€ app.py                  # Dashboard principal
â””â”€â”€ connectors/                 # Connecteurs JAR
```

## ğŸ”§ Services dÃ©ployÃ©s

| Service | Port | Description |
|---------|------|-------------|
| **namenode** | 9870, 8088, 7077, 8080 | HDFS NameNode + YARN ResourceManager + Spark Master |
| **secondary-nn** | 9868 | Secondary NameNode |
| **datanode-1/2/3** | 9864, 8042, 8081+ | HDFS DataNode + YARN NodeManager + Spark Worker |
| **spark-thrift** | 10000 | Spark Thrift Server (JDBC/SQL) |
| **metastore** | 5432 | Hive Metastore (PostgreSQL) |
| **mongodb** | 27017 | Base de donnÃ©es source |
| **mongo-express** | 8089 | Interface web MongoDB |
| **app** | 8501 | Dashboard Streamlit |

## ğŸ“Š Flux de donnÃ©es

### 1. **Ingestion** (MongoDB â†’ HDFS)
```python
# Script: spark/scripts/mongo_to_hdfs.py
spark.read.format("mongodb").load()  # Lecture MongoDB
  .write.parquet("hdfs:///data/raw/")  # Ã‰criture HDFS Parquet
```

### 2. **EDA avec Pig**
```pig
-- Script: pig/scripts/eda.pig
raw = LOAD 'hdfs:///data/raw/sales/' USING PigStorage(',');
by_category = GROUP raw BY category;
stats = FOREACH by_category GENERATE group, COUNT(raw), SUM(raw.total_amount);
STORE stats INTO 'hdfs:///data/curated/category_stats';
```

### 3. **Visualisation** (Streamlit)
```python
# App: app/app.py
# Connexion JDBC: jdbc:hive2://spark-thrift:10000/default
# Connexion MongoDB: mongodb://mongodb:27017
```

## ğŸ› ï¸ Commandes utiles

### Monitoring
```bash
# Voir l'Ã©tat des services
docker-compose ps

# Logs en temps rÃ©el
docker-compose logs -f namenode
docker-compose logs -f spark-thrift

# VÃ©rifier HDFS
docker exec namenode hdfs dfsadmin -report
```

### ExÃ©cution de jobs
```bash
# Lancer un job Spark
docker exec spark-thrift spark-submit /opt/spark/scripts/mongo_to_hdfs.py

# ExÃ©cuter un script Pig
docker exec pig pig -x mapreduce /scripts/eda.pig

# RequÃªte SQL via Spark Thrift
docker exec spark-thrift beeline -u jdbc:hive2://localhost:10000
```

### Gestion des donnÃ©es
```bash
# Lister les fichiers HDFS
docker exec namenode hdfs dfs -ls /data/

# Copier des fichiers
docker exec namenode hdfs dfs -put localfile /data/raw/

# Voir le contenu
docker exec namenode hdfs dfs -cat /data/curated/category_stats/part-r-00000
```

## ğŸ“ˆ Exemples d'utilisation

### 1. **Analyse des ventes par catÃ©gorie**
```sql
-- Via Spark Thrift Server
SELECT category, 
       COUNT(*) as nb_sales,
       SUM(total_amount) as revenue
FROM raw_sales 
GROUP BY category 
ORDER BY revenue DESC;
```

### 2. **Top utilisateurs**
```pig
-- Via Pig
users = LOAD 'hdfs:///data/raw/sales/' USING PigStorage(',');
by_user = GROUP users BY user_id;
user_totals = FOREACH by_user GENERATE group, SUM(users.total_amount);
top_users = ORDER user_totals BY $1 DESC;
STORE top_users INTO 'hdfs:///data/curated/top_users';
```

### 3. **Dashboard temps rÃ©el**
- Ouvrir http://localhost:8501
- Naviguer entre les diffÃ©rentes vues
- Filtrer et explorer les donnÃ©es

## ğŸ” Tests et validation

### Tests techniques
1. **MongoDB â†’ Spark** : VÃ©rifier la lecture des documents
2. **HDFS write** : Confirmer l'Ã©criture en Parquet
3. **Pig EDA** : Valider les agrÃ©gations
4. **Thrift JDBC** : Tester les requÃªtes SQL
5. **App Streamlit** : VÃ©rifier les visualisations

### Validation des donnÃ©es
```bash
# Compter les documents MongoDB
docker exec mongodb mongo retail --eval "db.sales.count()"

# VÃ©rifier les fichiers HDFS
docker exec namenode hdfs dfs -ls /data/raw/sales/

# Tester une requÃªte SQL
docker exec spark-thrift beeline -u jdbc:hive2://localhost:10000 -e "SELECT COUNT(*) FROM raw_sales;"
```

## ğŸš¨ DÃ©pannage

### ProblÃ¨mes courants

**1. Services ne dÃ©marrent pas**
```bash
# VÃ©rifier les logs
docker-compose logs [service-name]

# RedÃ©marrer un service
docker-compose restart [service-name]
```

**2. HDFS non accessible**
```bash
# VÃ©rifier l'Ã©tat du NameNode
docker exec namenode hdfs dfsadmin -safemode get

# Formater le NameNode (si nÃ©cessaire)
docker exec namenode hdfs namenode -format
```

**3. Spark Workers non connectÃ©s**
```bash
# VÃ©rifier la connectivitÃ© rÃ©seau
docker exec datanode-1 ping namenode

# RedÃ©marrer les workers
docker-compose restart datanode-1 datanode-2 datanode-3
```

**4. MongoDB non accessible**
```bash
# VÃ©rifier les logs MongoDB
docker-compose logs mongodb

# Tester la connexion
docker exec mongodb mongo --eval "db.adminCommand('ping')"
```

## ğŸ“š Ressources additionnelles

### Documentation
- [Hadoop 3.3.6](https://hadoop.apache.org/docs/r3.3.6/)
- [Spark 3.5.1](https://spark.apache.org/docs/3.5.1/)
- [Pig 0.17.0](https://pig.apache.org/docs/r0.17.0/)
- [MongoDB Spark Connector](https://docs.mongodb.com/spark-connector/)

### Extensions possibles
- **Zookeeper + JournalNodes** pour HA complet
- **MinIO/S3** pour le stockage objet
- **Airflow** pour l'orchestration
- **Grafana + Prometheus** pour le monitoring

## ğŸ“„ Licence

Ce projet est fourni Ã  des fins Ã©ducatives et de dÃ©monstration.

---

**Architecture dÃ©veloppÃ©e pour le cours de Traitement DistribuÃ©**  
*Hadoop + Spark + Pig + MongoDB + Streamlit*

